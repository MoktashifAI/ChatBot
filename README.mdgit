Thank you! Here's your `README.md` for **CyberSecGPT**, rewritten in the **exact same structure and format** as the example you provided:

---

# CyberSecGPT: Cybersecurity Chat Application

**CyberSecGPT** is a full-stack cybersecurity chat platform powered by LLMs. It offers secure document analysis, real-time chat, and persistent semantic memory, making it ideal for cybersecurity analysts and researchers. The application includes a Flask backend, React frontend, and MongoDB for data persistence.

---

## Features

* **JWT-Based Authentication**: Secure user login and registration system.
* **Multi-Conversation Support**: Create, rename, and delete chat sessions.
* **File Upload & Analysis**: Upload documents for LLM-assisted cybersecurity insights.
* **Real-Time Chat Interface**: Markdown and code highlighting supported.
* **Semantic Memory**: Pinecone-powered memory retrieval and MongoDB persistence.
* **Containerized Deployment**: Fully Dockerized setup for easy deployment.

---

## Project Structure

```
├── chat.py                # Flask backend (entry point)
├── requirements.txt       # Python dependencies
├── frontend/              # React frontend source code
│   ├── Dockerfile         # Frontend Dockerfile
│   └── ...
├── uploads/               # Uploaded files storage
├── docker-compose.yml     # Docker Compose configuration
├── Dockerfile             # Backend Dockerfile
└── .env                   # Environment variables file
```

---

## Installation

### Prerequisites

* Docker and Docker Compose
* (For manual development): Python 3.10+ and Node.js 14+

### Local Setup (Manual)

1. Clone the repository:

   ```bash
   git clone https://github.com/your-repo/cybersecgpt.git
   cd cybersecgpt
   ```

2. Create a `.env` file in the project root:

   ```bash
   MONGO_URI=mongodb://mongo:27017/vuln_analyzer
   JWT_SECRET=your_jwt_secret

   PINECONE_API_KEY=your_pinecone_api_key

   API_KEY=your_llm_api_key
   MODEL=your_model_name
   BASE_URL=https://api.llm-provider.com
   TEMPERATURE=0.6
   ```

3. Run the backend:

   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows use: venv\Scripts\activate
   pip install -r requirements.txt
   python chat.py
   ```

4. Run the frontend:

   ```bash
   cd frontend
   npm install
   npm start
   ```

---

## Docker Deployment

1. Clone the repository:

   ```bash
   git clone https://github.com/your-repo/cybersecgpt.git
   cd cybersecgpt
   ```

2. Create your `.env` file in the root directory (see [Installation](#installation)).

3. Build and run all services:

   ```bash
   docker-compose up --build
   ```

4. Access the application:

   * Frontend: [http://localhost:3000](http://localhost:3000)
   * Backend API: [http://localhost:5000](http://localhost:5000)
   * MongoDB: `localhost:27017`

---

## Environment Variables

These should be placed in a `.env` file at the project root:

```env
# MongoDB
MONGO_URI=mongodb://mongo:27017/vuln_analyzer
JWT_SECRET=your_jwt_secret

# Pinecone (for semantic memory)
PINECONE_API_KEY=your_pinecone_api_key

# LLM API (Groq/OpenAI)
API_KEY=your_llm_api_key
MODEL=your_model_name
BASE_URL=https://api.llm-provider.com
TEMPERATURE=0.6
```

---

## API Overview

The backend provides REST endpoints for:

* **User authentication** (`/register`, `/login`)
* **Chat management** (`/chats`, `/chats/:id`)
* **Message exchange** (`/chat/:id/message`)
* **File upload and analysis** (`/upload`)

*Documentation is accessible via Swagger or Postman collection (optional to add).*

---

## Notes

* Uploaded documents are stored in the `uploads/` folder (Docker volume).
* MongoDB data is persisted using Docker volume `mongo-data`.
* Frontend automatically proxies API calls to the backend on port `5000`.
* Make sure to use **strong secrets and keys in production** environments.

---

## License

MIT License — Feel free to modify and use as needed.

---

Let me know if you'd like to include:

* Swagger docs or OpenAPI schema
* Example `.env` file committed as `.env.example`
* Screenshots or usage videos
* CI/CD instructions (GitHub Actions, etc.)
